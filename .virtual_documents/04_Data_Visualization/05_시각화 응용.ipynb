


pip install wordcloud


from wordcloud import WordCloud
import matplotlib.pyplot as plt
import pandas as pd


df = pd.read_csv('data/naver_kin.txt', sep='\t')
df


# 코모란 품사표
# https://docs.komoran.kr/firststep/postypes.html
import pandas as pd
df = pd.read_csv('data/naver_kin_pos.txt', sep='\t') # by komoran
df.head(10)


len(df)


# NNP 고유명사 ,NNG 일반명사
df_flt = df.loc[(df['pos'] == 'NNP') | (df['pos'] == 'NNG'), ['query', 'no', 'token']] # 질문, 문장번호, 형태소
df_flt


df_flt2 = df_flt[['query', 'token']]
df_flt2


df_grp = df_flt2.groupby('query')['token'].apply(list)
df_grp


type(df_grp)


df_grp[0]


df_grp[0][:3]


data = str(df_grp[0]).replace("'", "")
data


data[:10]


# https://matplotlib.org/stable/tutorials/colors/colormaps.html
color_map = "Blues"
fontpath="C:/Windows/Fonts/malgun.ttf"


WordCloud?


wordcloud = WordCloud(
    background_color= 'white',
    colormap = color_map,
    collocations = False, # collocations : bigram처럼 token 2개를 붙여서 표시
    max_words= 200,
    max_font_size= 150,
    scale= 3, # scale : 제일 많은 token과 제일 적은 token 사이의 크기 차이
    random_state=777,
    font_path=fontpath).generate(data) # font_path : 폰트 경로 지정. 한글일 경우, 지정해주어야글자가 깨지지 않음.


wordcloud


plt.imshow(wordcloud)
plt.axis("off")
plt.show()


import numpy as np
from PIL import Image
mask_file = np.array(Image.open("data/heart.jpg"))


WordCloud?


wordcloud = WordCloud(
    background_color='white',
    colormap = 'RdBu',
    collocations = False, # collocations : bigram처럼 token 2개를 붙여서 표시
    max_words= 200,
    max_font_size= 150,
    scale= 3, # scale : 제일 많은 token과 제일 적은 token 사이의 크기 차이
    random_state=777,
    mask = mask_file,
    font_path=fontpath).generate(data) # font_path : 폰트 경로 지정. 한글일 경우, 지정해주어야글자가 깨지지 않음.


plt.imshow(wordcloud)
plt.axis("off")
plt.show()


wordcloud.to_file('data/wordcloud.jpg')





pip install folium


import folium
import pandas as pd


df = pd.read_csv('data/trade_apt_api_2023_address.txt', sep='\t')
df.head()


df.info()





df.head()


# 정수 형변환
df['거래금액'] = df['거래금액'].str.replace(',', '').replace(' ','').astype(int)
df['거래금액']


# 서울특별시 종로구 찾기
df['주소'] = '서울시 '+ df['지역명'] + ' ' +df['법정동'] + ' ' + df['지번']
df['주소'][:5]


df['지역명'] == '종로구'


df['기준년월'] >= 202301


df_jr = df.loc[(df['지역명'] == '종로구') & (df['기준년월']>=202301), :]
df_jr.head()


df_jr_grp = df_jr.groupby('주소')['거래금액'].mean()
df_jr_grp.head()


pip install geopy


# 지오코딩 라이브러리
from geopy.geocoders import Nominatim

geo_local = Nominatim(user_agent='South Korea')

def geocoding(address):
    try:
        geo = geo_local.geocode(address)
        x_y = [geo.latitude, geo.longitude]
        return x_y
    except:
        return [0, 0]


# 구글 37.573492  126.9791404 # 구글 맵에서 이차 확인
lat_start, lng_start = geocoding('서울시 종로구 종로1길 36')
lat_start, lng_start


lat_start, lng_start = geocoding('서울시 관악구 난곡로24바길 28')
lat_start, lng_start


folium.Map?


m = folium.Map(location=[37.573492, 126.9791404], zoom_start=15, tiles='cartodbpositron')
# m = folium.Map(location=[37.573492, 126.9791404], zoom_start=15, tiles='cartodbpositron', width=800, height=450)
# OpenStreetMap( ), Stamen Toner, cartodbpositron
m


m = folium.Map(location = [lat_start, lng_start], zoom_start=20, tiles ='OpenStreetMap' )

display(m)


lat = 37.4809165
lng = 127.0123303
m = folium.Map(location=[lat, lng], zoom_start=17, tiles='OpenStreetMap')

folium.Marker([lat, lng], popup="ESTSOFT", tooltip="Welcome to ESTSOFT", icon=folium.Icon(color='red', icon='glyphicon-heart')).add_to(m)
# https://getbootstrap.com/docs/3.3/components/
m


df_jr_grp


# 아파트 거래가 있는 주소, 거래금액를 지도에 표현해보자.

m = folium.Map(location =  [lat_start, lng_start], zoom_start=14, tiles ='OpenStreetMap')

for address, price in zip(df_jr_grp.index, df_jr_grp):
    lat, lng = geocoding(address)
    folium.Marker([lat, lng],
                  tooltip=price,
                  icon=folium.Icon(color='red', icon='glyphicon-ok')).add_to(m) # bootstrap icon
display(m)








import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import koreanize_matplotlib 
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# 주의 메시지 숨기기
import warnings
warnings.filterwarnings("ignore")


df = pd.read_csv('data/trade_apt_api_2023.txt', sep='\t')
# df['거래금액'] = df['거래금액'].str.replace(',', '').str.replace(' ', '').astype(int)
df.head()


# 강남구 추출
df_gn = df.loc[df['지역코드']==11680, :]
df_gn


df_gn.info()


df_gn['거래금액'] = df_gn['거래금액'].str.replace(',', '').str.replace(' ', '').astype(int)
df_gn.info()


# 평균 거래 금액
price_median = df_gn['거래금액'].median()
price_median


# 평균가 비교 라벨 추가
df_gn['구분'] = np.where(df_gn['거래금액'] >= price_median, 1, 0)
df_gn.head()


df_fit = df_gn[['건축년도', '전용면적', '층', '구분']]
df_fit.head()





# 상관 분석
corr= df_fit.corr()
corr


sns.heatmap(corr, annot=True, fmt=".1%", cmap='YlOrBr')
plt.show()





# x, y 데이터 분리
y = df_fit['구분']
X = df_fit.drop(['구분'], axis=1)
y.shape, X.shape


# 훈련/테스트 데이터 분리
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=777)
X_train.shape, X_test.shape, y_train.shape, y_test.shape


# 랜덤포레스트 모델링
model = RandomForestClassifier()
model.fit(X_train, y_train)
model


predictions = model.predict(X_test)
accuracy = accuracy_score(y_test, predictions)
accuracy





from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, predictions)
cm


tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()
tn, fp, fn, tp


sns.heatmap(cm, annot=True, fmt="d", cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Truth')
plt.show()





from sklearn.metrics import roc_curve, auc
y_scores = model.predict_proba(X_test)[:, 1]
fpr, tpr, thresholds = roc_curve(y_test, y_scores)
roc_auc = auc(fpr, tpr)
roc_auc


plt.plot(fpr, tpr, color='darkorange',
label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', linestyle='--')

plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(loc="lower right")
plt.show()





feature_importances_values = model.feature_importances_
feature_importances = pd.Series(feature_importances_values, index=X_train.columns)
feature_top = feature_importances.sort_values(ascending=True)
feature_top


model.feature_importances_


bars = plt.barh(feature_top.index, feature_top.values)
plt.show()





from tensorflow import keras
model = keras.models.Sequential()
model.add(keras.layers.Dense(64, activation='relu'))
model.add(keras.layers.Dense(32, activation='relu'))
model.add(keras.layers.Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='adam',  metrics=['accuracy'])
history = model.fit(X_train, y_train, validation_split=0.2, epochs=5, batch_size=32)


plt.figure(figsize=(9, 6))
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
# plt.plot(range(1, len(history.history['loss']) + 1), history.history['loss'])
# plt.plot(range(1, len(history.history['val_loss']) + 1), history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper right')
plt.show()





import plotly.express as px

fig = px.scatter_3d(df_gn, x='층', y='건축년도', z='전용면적', color='구분', symbol='구분', opacity=0.5, color_continuous_scale='Bluered')
fig.update_traces(marker=dict(size=3))
fig.show()
