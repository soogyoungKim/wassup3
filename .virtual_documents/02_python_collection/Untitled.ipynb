


pip install requests





import requests
from bs4 import BeautifulSoup


PATH = 'https://finance.naver.com/'
resp = requests.get(PATH)


# requests 응답 정봅 객체
resp


resp.text


print(resp.text)


src = resp.text


soup = BeautifulSoup(src, 'lxml') 
print(soup)


srclist = soup.select('.section_strategy a')
srclist


srclist = soup.select('.news_area a')
print(type(srclist))


# bs태그 객체들의 리스트
print(len(srclist))
print(srclist)


srclist = soup.select('.section_strategy li a')
len(srclist)


# 마지막 더보기 링크 제외
srclist = soup.select('.news_area a')[:-1]
srclist


# 첫번째 뉴스 데이터 추출
srclist[0].text


srclist[0]['href']





url = srclist[0]['href']


# //가 중복되는 문제처럼 생각보다 합치는게 번거로울 때가 있음
PATH + url


from urllib.parse import urljoin


urljoin(PATH, url)


srclist = soup.select('.news_area a')[:-1]
for list in srclist :
    title = item
    


# 제목과 url 데이터 목록 만들기
news_title= []
news_url = []
srclist = soup.select('.news_area a')[:-1]

for list in srclist :
    title = list.text
    url = urljoin(PATH, list['href'])
    print(title, url)

    news_title.append(title)
    news_url.append(url) 






import pandas as pd


df = pd.DataFrame({'제목':news_title, '주소':news_url})
df


print(df)


## 엑셀 파일 저장


# excel 파일 저장
df.to_excel('output/naver.xlsx', index=False)


import time
today = time.localtime()
today


df.to_excel(f"output/{today.tm_year}{today.tm_mon}{today.tm_mday}_naver.xlsx", index=False)


# 스트링포매팅으로 날짜포맷을 바꿔보자
# 2024-06-20
'%d-%02d-%02d' % (today.tm_year, today.tm_mon, today.tm_mday)


file_name = '%d-%02d-%02d' % (today.tm_year, today.tm_mon, today.tm_mday)
excel_name = file_name + '.xlsx'
csv_name = file_name + '.csv'
print(excel_name, csv_name)


df.to_csv(f'output/naver.xlsx', index=False)
