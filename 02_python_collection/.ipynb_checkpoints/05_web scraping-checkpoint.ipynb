{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171ed72f-6789-4b96-83ff-5bbf7c1aba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import urllib, math, time, os, pandas as pd\n",
    "\n",
    "options = Options()\n",
    "options.add_argument('--window-size=974,1047')\n",
    "options.add_argument('--window-position=953,0')\n",
    "options.add_experimental_option(\"detach\", True)\n",
    "\n",
    "search = input('검색어:')\n",
    "goal_cnt = int(input('스크래핑 할 건수는 몇건입니까?: '))\n",
    "page_cnt = math.ceil(goal_cnt / 10)  # 크롤링 할 전체 페이지 수 \n",
    "\n",
    "now = time.localtime()\n",
    "date_format = '%04d%02d%02d'%(now.tm_year, now.tm_mon, now.tm_mday)\n",
    "f_dir = f'{os.getcwd()}\\\\output\\\\{search}여행기사_{goal_cnt}건_{date_format}'\n",
    "os.makedirs(f_dir, exist_ok=True) # 디렉토리가 미리 존재해도 에러나지 않도록\n",
    "\n",
    "URL = 'https://korean.visitkorea.or.kr/search/search_list.do?keyword='+search\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get(URL)\n",
    "time.sleep(2)\n",
    "\n",
    "# 여행기사 더보기 클릭\n",
    "driver.find_element(By.CSS_SELECTOR, \"#s_recommend > .more_view > a\").click()\n",
    "time.sleep(2)\n",
    "\n",
    "contents_no = 1\n",
    "title_list = []\n",
    "contents_list = []\n",
    "img_url_list = []\n",
    "\n",
    "def page_work():\n",
    "    global contents_no, goal_cnt, title_list, contents_list, img_url_list\n",
    "    result = driver.find_elements(By.CSS_SELECTOR,'#search_result .tit>a')\n",
    "    \n",
    "    for i in range(0, len(result)):\n",
    "        if contents_no <= goal_cnt :    \n",
    "            \n",
    "            # 페이지 변경으로인한 DOM객체 변경 문제로 소스 다시 추출하기\n",
    "            result = driver.find_elements(By.CSS_SELECTOR,'#search_result .tit>a')\n",
    "            title = result[i].text\n",
    "            title_list.append(title)\n",
    "            \n",
    "            print(f'[{contents_no}] {title}') \n",
    "            \n",
    "            result[i].send_keys(Keys.ENTER) # .click()은 에러 잘남    \n",
    "            time.sleep(2)\n",
    "            \n",
    "            # 이미지 추출을 위해 미리 스크롤\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "            time.sleep(2)\n",
    "            \n",
    "            # 상세페이지 소스 추출\n",
    "            html = driver.page_source\n",
    "            html_dom = BeautifulSoup(html, 'lxml')\n",
    "          \n",
    "            img_tag_list = html_dom.select('.img_typeBox img')\n",
    "            img_url_list = [item['src'] for item in img_tag_list]\n",
    "\n",
    "            contents = driver.find_elements(By.CLASS_NAME, 'txt_p')\n",
    "            contents_merge = ' '.join([item.text for item in contents])        \n",
    "            contents_list.append(contents_merge)           \n",
    "            \n",
    "            driver.back()\n",
    "            time.sleep(2)     \n",
    "            contents_no += 1\n",
    "            \n",
    "        if contents_no % 50 == 0: # 5page 단위 도달 시 넥스트 버튼 클릭\n",
    "            driver.find_element(By.CSS_SELECTOR, '.btn_next').click()\n",
    "            # continue\n",
    "\n",
    "        \n",
    "        \n",
    "def file_export():\n",
    "    global contents_no\n",
    "    \n",
    "    df = pd.DataFrame({\"제목\":title_list, \"내용\":contents_list}, index=None)\n",
    "\n",
    "    filename = f'{search}여행기사_{goal_cnt}건_{date_format}.csv'\n",
    "    fileaddr = f_dir+'\\\\'+filename\n",
    "    \n",
    "    if not os.path.exists(fileaddr):\n",
    "        df.to_csv(fileaddr, index= False, mode='w', encoding='utf-8-sig')\n",
    "    else:\n",
    "        df.to_csv(fileaddr, index= False, mode='a', encoding='utf-8-sig', header=False)\n",
    "    \n",
    "    print(f'====== 콘텐츠 {contents_no-1}개, {filename} 파일 저장 완료 ======')\n",
    "    \n",
    "    img_no = 0\n",
    "    for src in img_url_list:\n",
    "        # 다운로드  (주소, 파일이름)\n",
    "        img_no += 1\n",
    "        urllib.request.urlretrieve(src, f'{f_dir}\\\\{page_no}_{img_no}.jpg')\n",
    "        \n",
    "    print(f'====== 이미지 {img_no}개 저장 완료 ======')\n",
    "\n",
    "today = time.localtime()\n",
    "print('스크래핑 프로그램 실행')\n",
    "\n",
    "for page_no in range(1, page_cnt+1):    \n",
    "    print(f'====== {page_no} 페이지 스크래핑 시작 ======')\n",
    "    page_work()\n",
    "    print(f'====== {page_no} 페이지 콘텐츠 저장 중 ======')\n",
    "    file_export()\n",
    "    print(f'====== {page_no} 페이지 스크래핑 완료 ======')\n",
    "    if page_no < page_cnt:\n",
    "        next_button = driver.find_element(By.CSS_SELECTOR, f\"a[id='{page_no+1}']\")\n",
    "        driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "        time.sleep(2)\n",
    "                   \n",
    "print('스크래핑 프로그램 종료')\n",
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
